# NLP Model Lab

> ä¸€ä¸ªä¸“ä¸šçš„NLPæ¨¡å‹è®­ç»ƒå’Œå¾®è°ƒæ¡†æ¶ï¼Œä¸“æ³¨äºBERTç­‰é¢„è®­ç»ƒæ¨¡å‹çš„å®é™…åº”ç”¨

## ğŸ“‹ é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æä¾›äº†ä¸€ä¸ªç»“æ„åŒ–ã€æ¨¡å—åŒ–çš„æ¡†æ¶ï¼Œç”¨äºè®­ç»ƒå’Œå¾®è°ƒå„ç§NLPæ¨¡å‹ã€‚å½“å‰å®ç°äº†åŸºäºBERTçš„æ„å›¾è¯†åˆ«ä»»åŠ¡ï¼Œåç»­å°†æ‰©å±•åˆ°æ›´å¤šä»»åŠ¡å’Œæ¨¡å‹ç±»å‹ã€‚

### ç‰¹æ€§

- ğŸ—ï¸ **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ¸…æ™°çš„ä»£ç ç»„ç»‡ï¼Œæ˜“äºæ‰©å±•å’Œç»´æŠ¤
- âš™ï¸ **é…ç½®é©±åŠ¨**ï¼šYAMLé…ç½®æ–‡ä»¶ï¼Œçµæ´»ç®¡ç†å®éªŒå‚æ•°
- ğŸ“Š **å®Œæ•´æµç¨‹**ï¼šæ•°æ®å¤„ç†ã€è®­ç»ƒã€è¯„ä¼°ã€æ¨ç†ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆ
- ğŸ”§ **å³ç”¨å‹å·¥å…·**ï¼šå¼€ç®±å³ç”¨çš„è®­ç»ƒè„šæœ¬å’Œå·¥å…·ç±»
- ğŸ“ˆ **å®éªŒè¿½è¸ª**ï¼šæ”¯æŒTensorBoardå’ŒWandBæ—¥å¿—è®°å½•

## ğŸ“ é¡¹ç›®ç»“æ„

```
nlp-model-lab/
â”œâ”€â”€ configs/              # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ base/            # åŸºç¡€é…ç½®
â”‚   â””â”€â”€ experiments/     # å®éªŒé…ç½®
â”œâ”€â”€ data/                # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ raw/            # åŸå§‹æ•°æ®
â”‚   â”œâ”€â”€ processed/      # å¤„ç†åçš„æ•°æ®
â”‚   â””â”€â”€ cache/          # ç¼“å­˜æ•°æ®
â”œâ”€â”€ scripts/             # è„šæœ¬ç›®å½•
â”‚   â”œâ”€â”€ train/          # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ eval/           # è¯„ä¼°è„šæœ¬
â”‚   â””â”€â”€ inference/      # æ¨ç†è„šæœ¬
â”œâ”€â”€ src/                 # æºä»£ç 
â”‚   â”œâ”€â”€ models/         # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ training/       # è®­ç»ƒç›¸å…³
â”‚   â”œâ”€â”€ data/           # æ•°æ®å¤„ç†
â”‚   â”œâ”€â”€ utils/          # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ inference/      # æ¨ç†ç›¸å…³
â””â”€â”€ outputs/            # è¾“å‡ºç›®å½•
    â”œâ”€â”€ checkpoints/    # æ¨¡å‹æ£€æŸ¥ç‚¹
    â”œâ”€â”€ logs/           # è®­ç»ƒæ—¥å¿—
    â””â”€â”€ results/        # å®éªŒç»“æœ
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå®‰è£…

#### ğŸ” ç¬¬ä¸€æ­¥ï¼šæ£€æµ‹ CUDA ç¯å¢ƒï¼ˆæ¨èï¼‰

```bash
# æ£€æµ‹ä½ çš„ GPU å’Œ CUDA é©±åŠ¨ç‰ˆæœ¬
python scripts/utils/check_cuda.py
```

è¿™ä¸ªå·¥å…·ä¼šæ¨èæœ€é€‚åˆä½ ç³»ç»Ÿçš„ PyTorch ç‰ˆæœ¬ã€‚**ç‰¹åˆ«è¯´æ˜**ï¼šCUDA é©±åŠ¨å‘ä¸‹å…¼å®¹ï¼Œä¾‹å¦‚ CUDA 13.0 é©±åŠ¨å¯ä»¥è¿è¡Œ CUDA 12.1 æˆ– 11.8 çš„ PyTorchã€‚

#### æ–¹å¼äºŒï¼šè‡ªåŠ¨å®‰è£…

**Linux/Mac:**
```bash
bash install.sh
```

**Windows:**
```powershell
.\install.ps1
```

å®‰è£…è„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹ä½ çš„ç³»ç»Ÿå¹¶å®‰è£…åˆé€‚çš„ç‰ˆæœ¬ã€‚

#### æ–¹å¼ä¸‰ï¼šæ‰‹åŠ¨å®‰è£…

è¯¦ç»†çš„å®‰è£…è¯´æ˜è¯·æŸ¥çœ‹ [INSTALLATION.md](INSTALLATION.md)

**å¿«é€Ÿå®‰è£…ï¼ˆä½¿ç”¨ Condaï¼‰:**
```bash
# 1. åˆ›å»ºç¯å¢ƒ
conda create -n nlp-lab python=3.10 -y
conda activate nlp-lab

# 2. å®‰è£… PyTorchï¼ˆæ ¹æ®ä½ çš„ç³»ç»Ÿé€‰æ‹©ï¼‰
# CPU ç‰ˆæœ¬ï¼š
conda install pytorch torchvision torchaudio cpuonly -c pytorch -y

# GPU ç‰ˆæœ¬ï¼ˆCUDA 12.8ï¼Œæ¨èï¼‰ï¼š
conda install pytorch torchvision torchaudio pytorch-cuda=12.8 -c pytorch -c nvidia -y

# GPU ç‰ˆæœ¬ï¼ˆCUDA 12.1ï¼Œå¤‡é€‰ï¼‰ï¼š
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia -y

# GPU ç‰ˆæœ¬ï¼ˆCUDA 11.8ï¼Œå…¼å®¹ï¼‰ï¼š
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y

# 3. å®‰è£…å…¶ä»–ä¾èµ–
pip install -r requirements-core.txt
```

**å¿«é€Ÿå®‰è£…ï¼ˆä½¿ç”¨ pipï¼‰:**
```bash
# CPU ç‰ˆæœ¬ï¼š
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install -r requirements-core.txt

# GPU ç‰ˆæœ¬ï¼ˆCUDA 12.8ï¼Œæ¨èï¼‰ï¼š
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
pip install -r requirements-core.txt

# GPU ç‰ˆæœ¬ï¼ˆCUDA 12.1ï¼Œå¤‡é€‰ï¼‰ï¼š
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements-core.txt

# GPU ç‰ˆæœ¬ï¼ˆCUDA 11.8ï¼Œå…¼å®¹ï¼‰ï¼š
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements-core.txt
```

### 2. å‡†å¤‡æ•°æ®

åˆ›å»ºç¤ºä¾‹æ•°æ®ç”¨äºæµ‹è¯•ï¼š

```bash
python -m src.data.preprocessors
```

è¿™å°†åœ¨ `data/processed/` ç›®å½•ä¸‹ç”Ÿæˆè®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†ã€‚

### 3. è®­ç»ƒæ¨¡å‹

```bash
# ä½¿ç”¨é»˜è®¤é…ç½®è®­ç»ƒ
python scripts/train/train_intent_classification.py --config configs/experiments/intent_classification_customer_service.yaml

# è°ƒè¯•æ¨¡å¼ï¼ˆä½¿ç”¨å°‘é‡æ•°æ®å¿«é€Ÿæµ‹è¯•ï¼‰
python scripts/train/train_intent_classification.py \
    --config configs/experiments/intent_classification_customer_service.yaml \
    --debug
```

### 4. è¯„ä¼°æ¨¡å‹

```bash
python scripts/eval/evaluate_intent.py \
    --checkpoint outputs/exp_001_bert_intent \
    --test_file data/processed/intent_test.json \
    --output_dir outputs/eval_results
```

### 5. æ¨¡å‹æ¨ç†

```bash
# äº¤äº’å¼æ¨¡å¼
python scripts/inference/predict_intent.py \
    --checkpoint outputs/exp_001_bert_intent \
    --interactive

# é¢„æµ‹å•ä¸ªæ–‡æœ¬
python scripts/inference/predict_intent.py \
    --checkpoint outputs/exp_001_bert_intent \
    --text "æŸ¥è¯¢é“¶è¡Œå¡ä½™é¢"

# æ‰¹é‡é¢„æµ‹
python scripts/inference/predict_intent.py \
    --checkpoint outputs/exp_001_bert_intent \
    --input data/raw/test_data.json \
    --output outputs/predictions.json
```

## ğŸ“Š ä½¿ç”¨ç¤ºä¾‹

### è‡ªå®šä¹‰æ•°æ®é›†

1. å‡†å¤‡JSONæ ¼å¼æ•°æ®ï¼š

```json
[
  {
    "text": "æŸ¥è¯¢é“¶è¡Œå¡ä½™é¢",
    "intent": "query_balance"
  },
  {
    "text": "è½¬è´¦ç»™æœ‹å‹",
    "intent": "transfer_money"
  }
]
```

2. ä½¿ç”¨é¢„å¤„ç†å™¨å¤„ç†æ•°æ®ï¼š

```python
from src.data import IntentDataPreprocessor

preprocessor = IntentDataPreprocessor(
    input_file="./data/raw/my_data.json",
    output_dir="./data/processed",
    test_size=0.2,
    val_size=0.1
)

train_path, val_path, test_path = preprocessor.process()
```

3. åˆ›å»ºæ–°çš„é…ç½®æ–‡ä»¶ï¼Œä¿®æ”¹æ•°æ®è·¯å¾„å’Œæ ‡ç­¾æ•°é‡

4. å¼€å§‹è®­ç»ƒï¼

### è‡ªå®šä¹‰è®­ç»ƒé…ç½®

ç¼–è¾‘ `configs/experiments/` ä¸­çš„é…ç½®æ–‡ä»¶ï¼š

```yaml
model:
  num_labels: 10  # ä½ çš„ç±»åˆ«æ•°é‡

training:
  num_epochs: 5
  batch_size: 32
  learning_rate: 3.0e-5
  warmup_ratio: 0.1
```

## ğŸ¯ æ”¯æŒçš„ä»»åŠ¡

- [x] **æ„å›¾è¯†åˆ«**ï¼ˆIntent Classificationï¼‰
  - [x] BERT-base-chinese
  - [ ] RoBERTa
  - [ ] ERNIE
- [ ] æ–‡æœ¬åˆ†ç±»
- [ ] å‘½åå®ä½“è¯†åˆ«
- [ ] å…³ç³»æŠ½å–
- [ ] é—®ç­”ç³»ç»Ÿ

## ğŸ”§ é«˜çº§åŠŸèƒ½

### ä½¿ç”¨LoRAè¿›è¡Œå‚æ•°é«˜æ•ˆå¾®è°ƒ

```python
# åœ¨é…ç½®æ–‡ä»¶ä¸­å¯ç”¨LoRA
training:
  strategy: "lora"

lora:
  r: 16
  lora_alpha: 32
  target_modules: ["query", "value"]
  dropout: 0.05
```

### åˆ†å¸ƒå¼è®­ç»ƒ

```bash
# ä½¿ç”¨Accelerate
accelerate config
accelerate launch scripts/train/train_intent_classification.py --config xxx.yaml

# ä½¿ç”¨DeepSpeed
deepspeed --num_gpus=2 scripts/train/train_intent_classification.py --config xxx.yaml
```

### å®éªŒè¿½è¸ª

```bash
# å¯ç”¨WandB
export WANDB_API_KEY=your_key
python scripts/train/train_intent_classification.py --config xxx.yaml
```

## ğŸ“š å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„æ¨¡å‹ç±»å‹

1. åœ¨ `src/models/` ä¸‹åˆ›å»ºæ–°æ¨¡å—
2. ç»§æ‰¿ `BaseTrainer` ç±»
3. å®ç°ç›¸å…³æ–¹æ³•
4. æ·»åŠ å¯¹åº”çš„è®­ç»ƒè„šæœ¬

### æ·»åŠ æ–°çš„æ•°æ®é›†ç±»

1. åœ¨ `src/data/datasets.py` ä¸­ç»§æ‰¿ `IntentClassificationDataset`
2. å®ç° `_load_data` æ–¹æ³•
3. æ›´æ–°æ–‡æ¡£

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Forkæœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ™ è‡´è°¢

- [Hugging Face Transformers](https://github.com/huggingface/transformers)
- [PyTorch](https://github.com/pytorch/pytorch)

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·æäº¤ [Issue](https://github.com/yourusername/nlp-model-lab/issues)

---

**æ³¨æ„**ï¼šæœ¬é¡¹ç›®æ­£åœ¨ç§¯æå¼€å‘ä¸­ï¼ŒAPIå¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–ã€‚å»ºè®®åœ¨ç”Ÿäº§ç¯å¢ƒä½¿ç”¨å‰è¿›è¡Œå……åˆ†æµ‹è¯•ã€‚
